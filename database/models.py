"""
STACD Database Models - 5-table design
Following STACD research paper specification
"""

from sqlalchemy import Column, String, Integer, Float, DateTime, JSON, ForeignKey, Boolean, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime

Base = declarative_base()


class DAG(Base):
    """
    DAG Registry - stores workflow definitions
    """
    __tablename__ = 'dags'
    
    dag_uuid = Column(String(36), primary_key=True)  # UUID generated by DAG generator
    dag_id = Column(String(100), nullable=False)     # e.g., "new_backend_api_test"
    name = Column(String(200), nullable=False)
    version = Column(String(20), nullable=False)     # e.g., "1.0"
    description = Column(Text)
    structure = Column(JSON)                         # Full DAG structure (nodes, edges)
    parameters = Column(JSON)                        # DAG-level parameters
    created_at = Column(DateTime, default=datetime.utcnow)
    is_active = Column(Boolean, default=True)
    
    # Relationships
    algorithm_instances = relationship("AlgorithmInstance", back_populates="dag")
    dataset_instances = relationship("DatasetInstance", back_populates="dag")
    
    def __repr__(self):
        return f"<DAG(uuid={self.dag_uuid}, id={self.dag_id}, version={self.version})>"


class AlgorithmType(Base):
    """
    Algorithm Registry - catalog of algorithm types/versions
    """
    __tablename__ = 'algorithm_types'
    
    algo_type_id = Column(Integer, primary_key=True, autoincrement=True)
    algo_name = Column(String(100), nullable=False)   # e.g., "LULC_Algorithm"
    version = Column(String(20), nullable=False)      # e.g., "1.0"
    description = Column(Text)
    params_schema = Column(JSON)                      # Expected parameters
    api_url = Column(String(500))                     # API endpoint
    docker_image = Column(String(200))                # Docker image reference
    execution_mode = Column(String(20))               # "api" or "docker"
    created_at = Column(DateTime, default=datetime.utcnow)
    is_active = Column(Boolean, default=True)
    
    # Relationships
    algorithm_instances = relationship("AlgorithmInstance", back_populates="algorithm_type")
    
    def __repr__(self):
        return f"<AlgorithmType(name={self.algo_name}, version={self.version})>"


class AlgorithmInstance(Base):
    """
    Algorithm Execution Log - actual runs with UUIDs
    """
    __tablename__ = 'algorithm_instances'
    
    execution_id = Column(String(36), primary_key=True)  # UUID from Airflow
    algo_type_id = Column(Integer, ForeignKey('algorithm_types.algo_type_id'), nullable=False)
    dag_uuid = Column(String(36), ForeignKey('dags.dag_uuid'), nullable=False)
    dag_run_id = Column(String(200))                     # Airflow's DAG run ID
    node_name = Column(String(100), nullable=False)      # Task ID in DAG
    status = Column(String(20), nullable=False)          # "running", "success", "failed"
    parameters = Column(JSON)                            # Actual params used
    execution_time = Column(Float)                       # Seconds
    started_at = Column(DateTime, default=datetime.utcnow)
    completed_at = Column(DateTime)
    error_message = Column(Text)
    
    # Relationships
    algorithm_type = relationship("AlgorithmType", back_populates="algorithm_instances")
    dag = relationship("DAG", back_populates="algorithm_instances")
    dataset_instances = relationship("DatasetInstance", back_populates="algorithm_instance")
    
    def __repr__(self):
        return f"<AlgorithmInstance(id={self.execution_id}, node={self.node_name}, status={self.status})>"


class DatasetType(Base):
    """
    Dataset Registry - catalog of dataset types/versions
    """
    __tablename__ = 'dataset_types'
    
    dataset_type_id = Column(Integer, primary_key=True, autoincrement=True)
    dataset_name = Column(String(100), nullable=False)   # e.g., "LULC_Raster"
    version = Column(String(20), nullable=False)         # e.g., "1.0"
    description = Column(Text)
    schema = Column(JSON)                                # Dataset structure/bands
    produced_by_algo = Column(String(100))               # Which algorithm creates this
    storage_pattern = Column(String(500))                # GEE asset path template
    created_at = Column(DateTime, default=datetime.utcnow)
    is_active = Column(Boolean, default=True)
    
    # Relationships
    dataset_instances = relationship("DatasetInstance", back_populates="dataset_type")
    
    def __repr__(self):
        return f"<DatasetType(name={self.dataset_name}, version={self.version})>"


class DatasetInstance(Base):
    """
    Dataset Instance - actual datasets created with UUIDs
    """
    __tablename__ = 'dataset_instances'
    
    dataset_uuid = Column(String(36), primary_key=True)  # UUID from Airflow
    dataset_type_id = Column(Integer, ForeignKey('dataset_types.dataset_type_id'), nullable=False)
    execution_id = Column(String(36), ForeignKey('algorithm_instances.execution_id'), nullable=False)
    dag_uuid = Column(String(36), ForeignKey('dags.dag_uuid'), nullable=False)
    node_name = Column(String(100), nullable=False)      # Task ID in DAG
    asset_ids = Column(JSON, nullable=False)             # List of GEE asset paths
    region_params = Column(JSON)                         # state, district, block, years
    created_at = Column(DateTime, default=datetime.utcnow)
    status = Column(String(20), default="active")        # "active", "deprecated", "deleted"
    
    # Relationships
    dataset_type = relationship("DatasetType", back_populates="dataset_instances")
    algorithm_instance = relationship("AlgorithmInstance", back_populates="dataset_instances")
    dag = relationship("DAG", back_populates="dataset_instances")
    
    def __repr__(self):
        return f"<DatasetInstance(uuid={self.dataset_uuid}, node={self.node_name})>"
